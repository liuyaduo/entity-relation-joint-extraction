NYT

| 论文                           | prec     | recall   | F1       | 是否使用BERT | 代码链接                                                     |
| ------------------------------ | -------- | -------- | -------- | ------------ | ------------------------------------------------------------ |
| attention as relation（SMHSA） | 88.1%    | 78.5%    | 83.0%    | 无           | https://github.com/chenshaowei57/SMHSA                       |
| RIN                            | 83.9±0.5 | 85.5±0.5 | 84.7±0.4 | 无           | https://github.com/BDBC-KG-NLP/Recurrent_Interaction_Network_EMNLP2020 |
|                                |          |          |          |              |                                                              |



ACE04

| 论文           | **NER MICRO F1** | **RE MICRO F1** | **RE+ MICRO F1** | 是否使用BERT       | 代码链接                                                     |
| -------------- | ---------------- | --------------- | ---------------- | ------------------ | ------------------------------------------------------------ |
| multi-head     | 81.6             |                 | 47.14            | 否                 | https://github.com/bekou/multihead_joint_entity_relation_extraction |
| Tabel-Sequence | 88.6             | 63.3            | 59.6             | 使用BERT预训练权重 | https://github.com/LorrinWWW/two-are-better-than-one         |
|                |                  |                 |                  |                    |                                                              |

